{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  60+ degrees in February in Nebraska? \n",
    "It's going to be crazy warm today in Lincoln, Neb. -- the forecast high is only two degrees below the record of 70 for the day. That's not shocking for a Spring day, but for February, it's quite surprising. It's still Winter in a place that earns a capital W on Winter. \n",
    "\n",
    "But how crazy it is? Let's find out.\n",
    "\n",
    "First, we need some data. [The National Centers for Environmental Information at NOAA](http://www.ncdc.noaa.gov/) has a mind boggling amount of climate data, and it's easy to query and download (though, warning, downloads aren't instantaneous: you have to order the data and it's processed as they get it). I've downloaded every weather station in Lincoln for the past 50 years. That'll be overkill -- I'll cull the herd later -- but for now, it's a good solid chunk of data.\n",
    "\n",
    "We'll use Agate to analyze the data and answer one simple question: How often does it get to be 60 degrees or more in February in Lincoln? First, some preliminaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import agate\n",
    "\n",
    "tester = agate.TypeTester(limit=100)\n",
    "\n",
    "fiftyyears = agate.Table.from_csv('../Data/temp1.csv', column_types=tester)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tester` bits just tells Agate to interpolate field types only using the first 100 rows of data. That speeds up the importing of a 3.5 MB text file a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|---------------+---------------|\n",
      "|  column_names | column_types  |\n",
      "|---------------+---------------|\n",
      "|  STATION      | Text          |\n",
      "|  STATION_NAME | Text          |\n",
      "|  ELEVATION    | Number        |\n",
      "|  LATITUDE     | Number        |\n",
      "|  LONGITUDE    | Number        |\n",
      "|  Date         | Date          |\n",
      "|  TMAX         | Number        |\n",
      "|  TMIN         | Number        |\n",
      "|---------------+---------------|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fiftyyears)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, TMAX and TMIN -- the high and low temperatures for the day -- are represented without the decimal, and they're in Celsius. This being the United States of Fahrenheit, we have to convert it.\n",
    "\n",
    "The general formula for converting C to F is `TempInC * 1.8 + 32` but, in our case, we need to first divide our temp by 10 to get that decimal back.\n",
    "\n",
    "To do all of this in one fell swoop, we'll use Agate's Formula capabilities to create a new column of data called `tmax_f` and `tmin_f` which will be what they say on the tin -- the high and low temps in Fahrenheit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "def make_high_f(row):\n",
    "    return ((row['TMAX']/10)*Decimal(1.8)+32).quantize(Decimal('0.1'))\n",
    "\n",
    "def make_low_f(row):\n",
    "    return ((row['TMIN']/10)*Decimal(1.8)+32).quantize(Decimal('0.1'))\n",
    "\n",
    "converted_temps = fiftyyears.compute([\n",
    "    ('tmax_f', agate.Formula(agate.Number(), make_high_f)),\n",
    "    ('tmin_f', agate.Formula(agate.Number(), make_high_f))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|---------------+---------------|\n",
      "|  column_names | column_types  |\n",
      "|---------------+---------------|\n",
      "|  STATION      | Text          |\n",
      "|  STATION_NAME | Text          |\n",
      "|  ELEVATION    | Number        |\n",
      "|  LATITUDE     | Number        |\n",
      "|  LONGITUDE    | Number        |\n",
      "|  Date         | Date          |\n",
      "|  TMAX         | Number        |\n",
      "|  TMIN         | Number        |\n",
      "|  tmax_f       | Number        |\n",
      "|  tmin_f       | Number        |\n",
      "|---------------+---------------|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(converted_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since we're only concerned with the month of February, we need to be able to filter out other months. I'm just learning Agate, and the way I know how to do this is to create a field with the month in it and filter on that. We do that similar to our Fahrenheit fields: with Formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temps_with_months = converted_temps.compute([\n",
    "    ('month', agate.Formula(agate.Text(), lambda row: '%s' % row['Date'].month))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|---------------+---------------|\n",
      "|  column_names | column_types  |\n",
      "|---------------+---------------|\n",
      "|  STATION      | Text          |\n",
      "|  STATION_NAME | Text          |\n",
      "|  ELEVATION    | Number        |\n",
      "|  LATITUDE     | Number        |\n",
      "|  LONGITUDE    | Number        |\n",
      "|  Date         | Date          |\n",
      "|  TMAX         | Number        |\n",
      "|  TMIN         | Number        |\n",
      "|  tmax_f       | Number        |\n",
      "|  tmin_f       | Number        |\n",
      "|  month        | Text          |\n",
      "|---------------+---------------|\n",
      "\n",
      "43551\n"
     ]
    }
   ],
   "source": [
    "print(temps_with_months)\n",
    "print(len(temps_with_months.rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you were following along, you saw that I printed the number of rows in the table we're working with: 43,551. So that means we have more than 43,000 weather observations across the city since 1966. So let's cut that pile down a bit. We don't need to count every 60 degree reading at every weather station, so let's just use the official weather station in town at the Lincoln Airport. I'm going to filter it out by the Station ID of the Airport. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15872\n"
     ]
    }
   ],
   "source": [
    "airport = temps_with_months.where(lambda row: row['STATION'] == 'GHCND:USW00014939')\n",
    "print(len(airport.rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we're down to 15,872 weather observations since 1966. We just want February. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228\n"
     ]
    }
   ],
   "source": [
    "airport_feb = airport.where(lambda row: row['month'] == '2')\n",
    "print(len(airport_feb.rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a time for a reality check. If you just took 28 times 50, you'd get 1,400. Every four years, there's 29 days in February, so something's amiss here. It means we don't have all the data we think we have. Indeed, if you look at the data, you'll see there's only airport data going back to September 1972. Which means for our purposes, it's 1973 -- the first February we'd encounter. So instead of 50 years, we have 43. \n",
    "\n",
    "If you want to see how many February days in the 60s we've had at the airport since 1973, it's 88."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "warm_feb_days = airport_feb.where(lambda row: 60 <= row['tmax_f'] < 70)\n",
    "print(len(warm_feb_days.rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that a little more graphically, we can bin the temps and `print_bars` instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmax_f      count\n",
      "[-20 - -10)     0 ▓                               \n",
      "[-10 - 0)       3 ▓                               \n",
      "[0 - 10)       22 ▓░░                             \n",
      "[10 - 20)     103 ▓░░░░░░░░                       \n",
      "[20 - 30)     203 ▓░░░░░░░░░░░░░░░░               \n",
      "[30 - 40)     355 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░   \n",
      "[40 - 50)     233 ▓░░░░░░░░░░░░░░░░░░             \n",
      "[50 - 60)     199 ▓░░░░░░░░░░░░░░░                \n",
      "[60 - 70)      88 ▓░░░░░░░                        \n",
      "[70 - 80)      22 ▓░░                             \n",
      "[80 - 90]       0 ▓                               \n",
      "                  +-------+-------+------+-------+\n",
      "                  0      100     200    300    400\n"
     ]
    }
   ],
   "source": [
    "binned_temps = airport_feb.bins('tmax_f', 11, -20, 90)\n",
    "binned_temps.print_bars('tmax_f', 'count', width=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the next question I have is when have those 88 days occurred? Were they all recent and a scary sign of climate change? Or was there a February or two in the past that were off-the-charts warm? We've got the data. Let's find out. First we'll add a year field to our warm days dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warm_feb_days_with_years = warm_feb_days.compute([\n",
    "    ('year', agate.Formula(agate.Text(), lambda row: '%s' % row['Date'].year))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll group those together into unique years and then count them up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warm_feb_days_with_years = warm_feb_days.compute([\n",
    "    ('year', agate.Formula(agate.Text(), lambda row: '%s' % row['Date'].year))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_year = warm_feb_days_with_years.group_by('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_year_count = by_year.aggregate([\n",
    "    ('count', agate.Length())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year count\n",
      "1974     2 ▓░░░░░░░░░░                            \n",
      "1976     6 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░          \n",
      "1977     8 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n",
      "1981     6 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░          \n",
      "1982     2 ▓░░░░░░░░░░                            \n",
      "1983     1 ▓░░░░░                                 \n",
      "1984     3 ▓░░░░░░░░░░░░░░                        \n",
      "1986     2 ▓░░░░░░░░░░                            \n",
      "1987     4 ▓░░░░░░░░░░░░░░░░░░░                   \n",
      "1988     1 ▓░░░░░                                 \n",
      "1990     3 ▓░░░░░░░░░░░░░░                        \n",
      "1991     3 ▓░░░░░░░░░░░░░░                        \n",
      "1992     5 ▓░░░░░░░░░░░░░░░░░░░░░░░░              \n",
      "1994     2 ▓░░░░░░░░░░                            \n",
      "1995     3 ▓░░░░░░░░░░░░░░                        \n",
      "1996     3 ▓░░░░░░░░░░░░░░                        \n",
      "1997     2 ▓░░░░░░░░░░                            \n",
      "1998     1 ▓░░░░░                                 \n",
      "1999     4 ▓░░░░░░░░░░░░░░░░░░░                   \n",
      "2000     7 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░     \n",
      "2005     6 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░          \n",
      "2006     3 ▓░░░░░░░░░░░░░░                        \n",
      "2007     1 ▓░░░░░                                 \n",
      "2009     5 ▓░░░░░░░░░░░░░░░░░░░░░░░░              \n",
      "2011     2 ▓░░░░░░░░░░                            \n",
      "2012     1 ▓░░░░░                                 \n",
      "2013     1 ▓░░░░░                                 \n",
      "2014     1 ▓░░░░░                                 \n",
      "           +---------+--------+--------+---------+\n",
      "           0         2        4        6         8\n"
     ]
    }
   ],
   "source": [
    "by_year_count.print_bars('year', 'count', width=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a few years had some warm days. What about the average? Is it going up? Do warm days have an outsize impact? How do we calculate an average for February by year to compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_february = airport_feb.compute([\n",
    "    ('year', agate.Formula(agate.Text(), lambda row: '%s' % row['Date'].year))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_feb_by_year = average_february.group_by('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_feb_by_year = average_feb_by_year.aggregate([\n",
    "    ('average', agate.Mean('tmax_f'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                       average\n",
      "1973 36.80000000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░                 \n",
      "1974 41.85357142857142857142857143 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░             \n",
      "1975 28.27857142857142857142857143 ▓░░░░░░░░░░░░░░░░░░░░░                       \n",
      "1976 50.33793103448275862068965517 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░       \n",
      "1977 47.46785714285714285714285714 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░         \n",
      "1978 22.75000000000000000000000000 ▓░░░░░░░░░░░░░░░░░                           \n",
      "1979 23.27857142857142857142857143 ▓░░░░░░░░░░░░░░░░░                           \n",
      "1980 30.73448275862068965517241379 ▓░░░░░░░░░░░░░░░░░░░░░░░                     \n",
      "1981 45.22500000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "1982 33.10000000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░                    \n",
      "1983 39.96071428571428571428571429 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░               \n",
      "1984 46.35517241379310344827586207 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░          \n",
      "1985 33.38214285714285714285714286 ▓░░░░░░░░░░░░░░░░░░░░░░░░                    \n",
      "1986 35.79285714285714285714285714 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░                  \n",
      "1987 49.60000000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░        \n",
      "1988 39.26206896551724137931034483 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░               \n",
      "1989 27.48928571428571428571428571 ▓░░░░░░░░░░░░░░░░░░░░                        \n",
      "1990 44.45714285714285714285714286 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "1991 51.40357142857142857142857143 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░      \n",
      "1992 48.57241379310344827586206897 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░        \n",
      "1993 28.90714285714285714285714286 ▓░░░░░░░░░░░░░░░░░░░░░                       \n",
      "1994 33.23214285714285714285714286 ▓░░░░░░░░░░░░░░░░░░░░░░░░                    \n",
      "1995 45.15357142857142857142857143 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "1996 43.13448275862068965517241379 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░            \n",
      "1997 38.12500000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░                \n",
      "1998 44.48571428571428571428571429 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "1999 48.36071428571428571428571429 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░         \n",
      "2000 49.20000000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░        \n",
      "2001 30.05000000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░                      \n",
      "2002 43.16071428571428571428571429 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░            \n",
      "2003 36.14285714285714285714285714 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░                 \n",
      "2004 35.01034482758620689655172414 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░                  \n",
      "2005 45.07500000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "2006 43.97500000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░            \n",
      "2007 33.25000000000000000000000000 ▓░░░░░░░░░░░░░░░░░░░░░░░░                    \n",
      "2008 36.51724137931034482758620690 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░                 \n",
      "2009 44.33214285714285714285714286 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░           \n",
      "2010 30.27857142857142857142857143 ▓░░░░░░░░░░░░░░░░░░░░░░                      \n",
      "2011 38.66428571428571428571428571 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░                \n",
      "2012 41.28275862068965517241379310 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░              \n",
      "2013 40.65714285714285714285714286 ▓░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░              \n",
      "2014 33.92142857142857142857142857 ▓░░░░░░░░░░░░░░░░░░░░░░░░░                   \n",
      "2015 33.58928571428571428571428571 ▓░░░░░░░░░░░░░░░░░░░░░░░░░                   \n",
      "2016 34.60714285714285714285714286 ▓░░░░░░░░░░░░░░░░░░░░░░░░░                   \n",
      "                                   +----------+----------+----------+----------+\n",
      "                                   0         15         30         45         60\n"
     ]
    }
   ],
   "source": [
    "average_feb_by_year.print_bars('year', 'average', width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most days over 60 happened in 1977, with eight, followed by 2000 with seven. In the 90s, there were seven straight years -- from 1994 to 2000 -- with at least one day in the 60s in February. \n",
    "\n",
    "So, is a day or two in the 60s in February unheard of? Not at all. But they aren't exactly common. So when it happens, GO OUTSIDE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
